{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "!pip install -q efficientnet\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from math import ceil, floor, log\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up constants\n",
    "SEED = 5\n",
    "N_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data and cut off bad quality ones\n",
    "df = pd.read_csv('labels.csv')\n",
    "df = df.query('photo_quality == 1')\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up models to be run\n",
    "MODELS = {\n",
    "          'ResNet50':[tf.keras.applications.ResNet50,32,300],\n",
    "          'DenseNet121':[tf.keras.applications.DenseNet121,32,300],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \\ with / to make the path work\n",
    "for idx in tqdm(df.index):    \n",
    "    df.loc[idx,'path']=df.loc[idx,'path'].replace('\\\\', '/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns we are interested in\n",
    "labels_cols = ['is_bee', 'is_wasp', 'is_otherinsect', 'is_other']\n",
    "\n",
    "#Split data into training, validation, and test data\n",
    "df_train = df.loc[(df.is_validation == 0) & (df.is_final_validation == 0)]\n",
    "df_valid = df.loc[(df.is_validation == 1)]\n",
    "df_test = df.loc[(df.is_final_validation == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.loc[:,['id']+labels_cols]\n",
    "y_train.set_index('id', inplace = True)\n",
    "y_valid = df_valid.loc[:,['id']+labels_cols]\n",
    "y_valid.set_index('id', inplace = True)\n",
    "y_test = df_test.loc[:,['id']+labels_cols]\n",
    "y_test.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lr_callback(plot=False):\n",
    "    start_lr = 0.001\n",
    "    def step_decay(epoch):\n",
    "        drop = 0.5\n",
    "        epochs_drop = 5.0\n",
    "        lr = start_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "        return lr\n",
    "    \n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "    if plot == True:\n",
    "        rng = [i for i in range(N_epochs)]\n",
    "        y = [step_decay(x) for x in rng]\n",
    "        plt.plot(rng, y)\n",
    "        plt.xlabel('epoch', size=14)\n",
    "        plt.ylabel('learning_rate', size=14)\n",
    "        plt.title('Training Schedule', size=16)\n",
    "        plt.show()\n",
    "        \n",
    "    return lr_callback\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n",
    "                                               monitor='val_loss',\n",
    "                                               verbose=1, \n",
    "                                               restore_best_weights=True)\n",
    "lr = get_lr_callback(plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Værdier til instantiering af ImageDataGenerator er taget fra eksemplet fundet under afsnittet 'Set up the Flowers dataset' på https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\n",
    "\n",
    "def gen_init(BS, IMG_Size):\n",
    "    #Vi normalisere trænings dataene\n",
    "    train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        width_shift_range=0.2, height_shift_range=0.2,\n",
    "        shear_range=0.2, zoom_range=0.2)\n",
    "\n",
    "    train_generator = train_gen.flow_from_dataframe(dataframe=df_train, \n",
    "                                                  x_col=\"path\", y_col=labels_cols, \n",
    "                                                  class_mode=\"raw\", \n",
    "                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n",
    "\n",
    "    #Data til validering skal ikke normaliseres, men vi skalerer det til samme opløsning som træningsdataene\n",
    "    valid_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)    \n",
    "    \n",
    "    \n",
    "    valid_generator = valid_gen.flow_from_dataframe(dataframe=df_valid,\n",
    "                                                  x_col=\"path\", y_col=labels_cols, \n",
    "                                                  class_mode=\"raw\", \n",
    "                                                  # class_mode=\"categorical\", \n",
    "                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n",
    "\n",
    "    #Data til test skal heller ikke normaliseres, men vi skalerer det ligeledes  \n",
    "    test_generator = valid_gen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                  x_col=\"path\", y_col=labels_cols, \n",
    "                                                  class_mode=\"raw\", \n",
    "                                                  shuffle = False,\n",
    "                                                  target_size=(IMG_Size,IMG_Size), batch_size = BS)\n",
    "\n",
    "    return   train_generator,   valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, valid_generator, test_generator = gen_init(32,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti, tl = train_generator.next()\n",
    "imgs = []\n",
    "for i in range(ti.shape[0]):\n",
    "    img = np.array(ti[i]*255, dtype = 'int32')\n",
    "    imgs.append(img)\n",
    "\n",
    "f, ax = plt.subplots(4, 8, figsize=(15,10))\n",
    "for i, img in enumerate(imgs):\n",
    "    ax[i//8, i%8].imshow(img)\n",
    "    ax[i//8, i%8].axis('off')\n",
    "    ax[i//8, i%8].set_title('label: %s' % tl[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_engine, IMG_Size):\n",
    "    inp = tf.keras.layers.Input(shape=(IMG_Size,IMG_Size,3))\n",
    "    base = model_engine(input_shape=(IMG_Size,IMG_Size,3),weights='imagenet',include_top=False)\n",
    "    x = base(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(4,activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inp,outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.001)   \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = []\n",
    "all_history = []\n",
    "all_preds = []\n",
    "all_accuracies = []\n",
    "all_recalls = []\n",
    "all_precisions = []\n",
    "all_confusion_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODELS:\n",
    "    engine = MODELS[model_name][0]\n",
    "    BS = MODELS[model_name][1]\n",
    "    IMG_Size = MODELS[model_name][2]\n",
    "    train_generator, valid_generator, test_generator = gen_init(BS, IMG_Size)\n",
    "    \n",
    "    model = build_model(engine, IMG_Size)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('Training model ', model_name)\n",
    "    history = model.fit(train_generator,\n",
    "              steps_per_epoch=len(df_train) / BS, epochs = N_epochs, verbose = 1,\n",
    "              callbacks=[es_callback, get_lr_callback(BS)],\n",
    "              validation_data = valid_generator)\n",
    "\n",
    "    model.save('model-%s.h5'%model_name)  \n",
    "    all_history.append(history)\n",
    "    \n",
    "    pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "    pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "    plt.show()\n",
    "\n",
    "    preds = model.predict(test_generator, verbose = 1)\n",
    "    all_preds.append(preds)\n",
    "    cm = confusion_matrix(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))\n",
    "    all_confusion_matrices.append(cm)\n",
    "    acc = accuracy_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))    \n",
    "    all_accuracies.append(acc)\n",
    "    prec = precision_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))    \n",
    "    all_precisions.append(prec)\n",
    "    recall = recall_score(np.argmax(np.array(y_test), axis=1), np.argmax(preds, axis = 1))    \n",
    "    all_recalls.append(recall)\n",
    "    \n",
    "    \n",
    "    print('------------------------------------------------------------------')\n",
    "    print(cm)\n",
    "    print(acc)\n",
    "    print(prec)\n",
    "    print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
